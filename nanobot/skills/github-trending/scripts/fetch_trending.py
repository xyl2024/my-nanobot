#!/usr/bin/env python3
"""
GitHub Trending çˆ¬è™«è„šæœ¬
è·å– GitHub æ¯æ—¥/æ¯å‘¨/æ¯æœˆçš„çƒ­é—¨é¡¹ç›®
"""

import argparse
import json
import re
import sys
from datetime import datetime, timedelta
from urllib.request import urlopen, Request
from urllib.error import URLError
from html import unescape

# GitHub Trending URL
BASE_URL = "https://github.com/trending"

# æ”¯æŒçš„æ—¶é—´èŒƒå›´
SINCE_OPTIONS = {
    "daily": "daily",
    "weekly": "weekly", 
    "monthly": "monthly"
}

# è¯·æ±‚å¤´ï¼Œæ¨¡æ‹Ÿæµè§ˆå™¨
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
    "Accept-Language": "en-US,en;q=0.5",
}


def build_url(language: str = None, since: str = "daily") -> str:
    """æ„å»º GitHub Trending URL"""
    url = BASE_URL
    params = []
    
    if since in SINCE_OPTIONS:
        params.append(f"since={SINCE_OPTIONS[since]}")
    if language:
        # URL ç¼–ç è¯­è¨€åç§°
        lang = language.lower().strip()
        # å¤„ç†è¯­è¨€åç§°ä¸­çš„ç©ºæ ¼
        lang = lang.replace(" ", "%20")
        url = f"{url}/{lang}"
    
    if params:
        url += "?" + "&".join(params)
    
    return url


def fetch_page(url: str) -> str:
    """è·å–ç½‘é¡µå†…å®¹"""
    try:
        req = Request(url, headers=HEADERS)
        with urlopen(req, timeout=30) as response:
            return response.read().decode("utf-8")
    except URLError as e:
        print(f"âŒ è·å–é¡µé¢å¤±è´¥: {e}", file=sys.stderr)
        sys.exit(1)


def parse_trending(html: str) -> list:
    """è§£æ HTML è·å– Trending é¡¹ç›®åˆ—è¡¨"""
    projects = []
    
    # åŒ¹é…æ¯ä¸ªä»“åº“æ¡ç›®
    # GitHub Trending é¡µé¢ç»“æ„
    article_pattern = r'<article class="Box-row">(.*?)</article>'
    articles = re.findall(article_pattern, html, re.DOTALL)
    
    for article in articles:
        try:
            # è·å–ä»“åº“åå’Œé“¾æ¥
            repo_pattern = r'<a href="([^"]+)"[^>]*>([^<]+)</a>'
            repo_match = re.search(repo_pattern, article)
            if not repo_match:
                continue
            
            repo_path = repo_match.group(1).strip()
            repo_name = repo_match.group(2).strip()
            
            # è·å–æè¿°
            desc_pattern = r'<p[^>]*class="[^"]*color-fg-muted[^"]*"[^>]*>([^<]+)</p>'
            desc_match = re.search(desc_pattern, article)
            description = ""
            if desc_match:
                description = unescape(desc_match.group(1).strip())
            
            # è·å–è¯­è¨€
            lang_pattern = r'<span[^>]*class="[^"]*color-fg-[^"]*"[^>]*>[^<]*</span>\s*<span[^>]*>([^<]+)</span>'
            lang_match = re.search(lang_pattern, article)
            language = lang_match.group(1).strip() if lang_match else "Unknown"
            
            # è·å– stars æ•°
            stars_pattern = r'aria-label="(\d+(?:\.\d+)?[kK]?) stars"'
            stars_match = re.search(stars_pattern, article)
            stars = stars_match.group(1) if stars_match else "0"
            
            # è·å–ä»Šæ—¥æ–°å¢ stars
            today_stars_pattern = r'(\d+(?:\.\d+)?[kK]?)\s*stars today'
            today_match = re.search(today_stars_pattern, article, re.IGNORECASE)
            stars_today = today_match.group(1) if today_match else "0"
            
            # æ„å»ºé¡¹ç›®ä¿¡æ¯
            project = {
                "name": repo_name,
                "path": repo_path,
                "url": f"https://github.com{repo_path}",
                "description": description,
                "language": language,
                "stars": stars,
                "stars_today": stars_today
            }
            projects.append(project)
            
        except Exception as e:
            # è·³è¿‡è§£æé”™è¯¯çš„æ¡ç›®
            continue
    
    return projects


def format_output(projects: list, language: str = None, since: str = "daily") -> str:
    """æ ¼å¼åŒ–è¾“å‡º"""
    if not projects:
        return "âš ï¸ æœªèƒ½è·å–åˆ°Trendingæ•°æ®ï¼Œè¯·ç¨åé‡è¯•"
    
    # è¯­è¨€æ˜¾ç¤º
    lang_display = f" - {language}" if language else ""
    
    # æ—¶é—´èŒƒå›´æ˜¾ç¤º
    since_display = {
        "daily": "ä»Šæ—¥",
        "weekly": "æœ¬å‘¨", 
        "monthly": "æœ¬æœˆ"
    }.get(since, "ä»Šæ—¥")
    
    output = []
    output.append(f"ğŸ”¥ GitHub Trending {since_display}{lang_display}")
    output.append("=" * 50)
    output.append("")
    
    for i, p in enumerate(projects[:25], 1):  # é™åˆ¶æ˜¾ç¤º25ä¸ª
        output.append(f"{i}. {p['name']}")
        output.append(f"   â­ {p['stars']} stars | +{p['stars_today']} today")
        if p['description']:
            # é™åˆ¶æè¿°é•¿åº¦
            desc = p['description'][:80] + "..." if len(p['description']) > 80 else p['description']
            output.append(f"   ğŸ“ {desc}")
        output.append(f"   ğŸ”— {p['url']}")
        output.append(f"   ğŸ–¥ï¸ {p['language']}")
        output.append("")
    
    output.append("=" * 50)
    output.append(f"å…± {len(projects)} ä¸ªé¡¹ç›®")
    
    return "\n".join(output)


def main():
    parser = argparse.ArgumentParser(description="è·å– GitHub Trending çƒ­é—¨é¡¹ç›®")
    parser.add_argument(
        "--daily", 
        action="store_true", 
        help="è·å–ä»Šæ—¥çƒ­é—¨ï¼ˆé»˜è®¤ï¼‰"
    )
    parser.add_argument(
        "--weekly", 
        action="store_true", 
        help="è·å–æœ¬å‘¨çƒ­é—¨"
    )
    parser.add_argument(
        "--monthly", 
        action="store_true", 
        help="è·å–æœ¬æœˆçƒ­é—¨"
    )
    parser.add_argument(
        "--language", 
        "-l",
        type=str,
        help="æŒ‡å®šç¼–ç¨‹è¯­è¨€ï¼ˆå¦‚ python, javascript, go, rustï¼‰"
    )
    parser.add_argument(
        "--json",
        action="store_true",
        help="è¾“å‡º JSON æ ¼å¼"
    )
    
    args = parser.parse_args()
    
    # ç¡®å®šæ—¶é—´èŒƒå›´
    if args.monthly:
        since = "monthly"
    elif args.weekly:
        since = "weekly"
    else:
        since = "daily"
    
    language = args.language
    
    # æ„å»º URL
    url = build_url(language, since)
    
    print(f"ğŸ“¡ æ­£åœ¨è·å– GitHub Trending ({since})...", file=sys.stderr)
    if language:
        print(f"   è¯­è¨€: {language}", file=sys.stderr)
    
    # è·å–é¡µé¢
    html = fetch_page(url)
    
    # è§£æ
    projects = parse_trending(html)
    
    # è¾“å‡º
    if args.json:
        print(json.dumps(projects, ensure_ascii=False, indent=2))
    else:
        print(format_output(projects, language, since))


if __name__ == "__main__":
    main()
